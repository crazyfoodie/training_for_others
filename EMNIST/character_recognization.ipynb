{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   775  776  777  778  \\\n",
       "0   45    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1   36    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2   43    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3   15    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    4    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('emnist-balanced-train.csv', header=None)\n",
    "test = pd.read_csv('emnist-balanced-test.csv', header=None)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9  ...  37  38  39  40  41  42  43  44  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "1   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "2   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   1   0   \n",
       "3   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "4   0   0   0   0   1   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "\n",
       "   45  46  \n",
       "0   1   0  \n",
       "1   0   0  \n",
       "2   0   0  \n",
       "3   0   0  \n",
       "4   0   0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now split labels and images from original dataframe.\n",
    "train_data = train.iloc[:, 1:]\n",
    "train_labels = train.iloc[:, 0]\n",
    "test_data = test.iloc[:, 1:]\n",
    "test_labels = test.iloc[:, 0]\n",
    "# one hot \n",
    "train_labels = pd.get_dummies(train_labels)\n",
    "test_labels = pd.get_dummies(test_labels)\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Turn our Dataframes into numpy array and delete train and test to save up memory.\n",
    "train_data = train_data.values\n",
    "train_labels = train_labels.values\n",
    "test_data = test_data.values\n",
    "test_labels = test_labels.values\n",
    "del train, test\n",
    "# For some reason, sadly, the EMNIST dataset was rotated and flipped and we need fix that.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(train_data[45].reshape([28, 28]), cmap='Greys_r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rotate(image):\n",
    "    image = image.reshape([28, 28])\n",
    "    image = np.fliplr(image)\n",
    "    image = np.rot90(image)\n",
    "    return image.reshape([28,28,1])\n",
    "    \n",
    "train_data = np.apply_along_axis(rotate, 1, train_data)/255\n",
    "test_data = np.apply_along_axis(rotate, 1, test_data)/255\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(train_data[45].reshape([28, 28]), cmap='Greys_r')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.layers import Input, Dense, Dropout, Reshape,Conv2D,Flatten,MaxPooling2D\n",
    "from keras.models import Model,load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               57700     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 47)                4747      \n",
      "=================================================================\n",
      "Total params: 96,079\n",
      "Trainable params: 96,079\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/demo/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "num_classes = 47\n",
    "inp = Input(shape=(28,28,1))\n",
    "#rel_input = Reshape((28,28,1))(inp)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu')(inp)\n",
    "c1 = Dropout(0.2)(c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='relu')(c1)\n",
    "c1 = MaxPooling2D(pool_size=(2, 2))(c1)\n",
    "c2 = Conv2D(32, (3, 3), activation='relu',padding=\"same\")(c1)\n",
    "c2 = Dropout(0.2)(c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='relu',padding=\"same\")(c2)\n",
    "c2 = MaxPooling2D(pool_size=(2, 2))(c2)\n",
    "c3 = Conv2D(64, (3, 3), activation='relu',padding=\"same\")(c2)\n",
    "c3 = MaxPooling2D(pool_size=(2, 2))(c3)\n",
    "f = Flatten()(c3)\n",
    "f = Dropout(0.3)(f)\n",
    "h1 = Dense(100, activation='relu')(f) \n",
    "h1 = Dropout(0.3)(h1)\n",
    "out = Dense(num_classes, activation='softmax')(h1) \n",
    "model = Model(input=inp, output=out)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feng/.conda/envs/test/lib/python3.6/site-packages/ipykernel/__main__.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 101520 samples, validate on 11280 samples\n",
      "Epoch 1/50\n",
      "101520/101520 [==============================] - 8s 80us/step - loss: 1.3157 - acc: 0.6098 - val_loss: 0.5031 - val_acc: 0.8243\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50307, saving model to model-emnist-nn0.h5\n",
      "Epoch 2/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.6143 - acc: 0.7951 - val_loss: 0.4144 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50307 to 0.41439, saving model to model-emnist-nn0.h5\n",
      "Epoch 3/50\n",
      "101520/101520 [==============================] - 5s 51us/step - loss: 0.5196 - acc: 0.8241 - val_loss: 0.3746 - val_acc: 0.8645\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.41439 to 0.37461, saving model to model-emnist-nn0.h5\n",
      "Epoch 4/50\n",
      "101520/101520 [==============================] - 5s 51us/step - loss: 0.4786 - acc: 0.8358 - val_loss: 0.3551 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.37461 to 0.35513, saving model to model-emnist-nn0.h5\n",
      "Epoch 5/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.4496 - acc: 0.8433 - val_loss: 0.3446 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.35513 to 0.34459, saving model to model-emnist-nn0.h5\n",
      "Epoch 6/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.4312 - acc: 0.8493 - val_loss: 0.3424 - val_acc: 0.8752\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.34459 to 0.34235, saving model to model-emnist-nn0.h5\n",
      "Epoch 7/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.4114 - acc: 0.8565 - val_loss: 0.3280 - val_acc: 0.8792\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34235 to 0.32803, saving model to model-emnist-nn0.h5\n",
      "Epoch 8/50\n",
      "101520/101520 [==============================] - 5s 53us/step - loss: 0.4014 - acc: 0.8575 - val_loss: 0.3210 - val_acc: 0.8813\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.32803 to 0.32101, saving model to model-emnist-nn0.h5\n",
      "Epoch 9/50\n",
      "101520/101520 [==============================] - 5s 54us/step - loss: 0.3888 - acc: 0.8610 - val_loss: 0.3251 - val_acc: 0.8804\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32101\n",
      "Epoch 10/50\n",
      "101520/101520 [==============================] - 5s 53us/step - loss: 0.3797 - acc: 0.8654 - val_loss: 0.3135 - val_acc: 0.8821\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32101 to 0.31352, saving model to model-emnist-nn0.h5\n",
      "Epoch 11/50\n",
      "101520/101520 [==============================] - 5s 54us/step - loss: 0.3753 - acc: 0.8656 - val_loss: 0.3222 - val_acc: 0.8794\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31352\n",
      "Epoch 12/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3700 - acc: 0.8669 - val_loss: 0.3105 - val_acc: 0.8827\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.31352 to 0.31052, saving model to model-emnist-nn0.h5\n",
      "Epoch 13/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3623 - acc: 0.8693 - val_loss: 0.3135 - val_acc: 0.8814\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31052\n",
      "Epoch 14/50\n",
      "101520/101520 [==============================] - 5s 53us/step - loss: 0.3555 - acc: 0.8715 - val_loss: 0.3094 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.31052 to 0.30938, saving model to model-emnist-nn0.h5\n",
      "Epoch 15/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3497 - acc: 0.8731 - val_loss: 0.3104 - val_acc: 0.8843\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.30938\n",
      "Epoch 16/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3467 - acc: 0.8739 - val_loss: 0.3098 - val_acc: 0.8833\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.30938\n",
      "Epoch 17/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3442 - acc: 0.8743 - val_loss: 0.3070 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.30938 to 0.30697, saving model to model-emnist-nn0.h5\n",
      "Epoch 18/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3411 - acc: 0.8755 - val_loss: 0.3018 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.30697 to 0.30183, saving model to model-emnist-nn0.h5\n",
      "Epoch 19/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3377 - acc: 0.8769 - val_loss: 0.3079 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.30183\n",
      "Epoch 20/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3357 - acc: 0.8781 - val_loss: 0.3088 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.30183\n",
      "Epoch 21/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3314 - acc: 0.8787 - val_loss: 0.3049 - val_acc: 0.8824\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.30183\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00033000001567415896.\n",
      "Epoch 22/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3101 - acc: 0.8841 - val_loss: 0.2960 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.30183 to 0.29603, saving model to model-emnist-nn0.h5\n",
      "Epoch 23/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3033 - acc: 0.8866 - val_loss: 0.2932 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.29603 to 0.29325, saving model to model-emnist-nn0.h5\n",
      "Epoch 24/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3007 - acc: 0.8884 - val_loss: 0.2930 - val_acc: 0.8883\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.29325 to 0.29296, saving model to model-emnist-nn0.h5\n",
      "Epoch 25/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.3000 - acc: 0.8895 - val_loss: 0.2924 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.29296 to 0.29242, saving model to model-emnist-nn0.h5\n",
      "Epoch 26/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.2985 - acc: 0.8890 - val_loss: 0.2927 - val_acc: 0.8886\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.29242\n",
      "Epoch 27/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.2965 - acc: 0.8894 - val_loss: 0.2922 - val_acc: 0.8877\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.29242 to 0.29220, saving model to model-emnist-nn0.h5\n",
      "Epoch 28/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.2946 - acc: 0.8909 - val_loss: 0.2907 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.29220 to 0.29072, saving model to model-emnist-nn0.h5\n",
      "Epoch 29/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.2908 - acc: 0.8912 - val_loss: 0.2926 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.29072\n",
      "Epoch 30/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.2928 - acc: 0.8905 - val_loss: 0.2901 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.29072 to 0.29012, saving model to model-emnist-nn0.h5\n",
      "Epoch 31/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.2915 - acc: 0.8914 - val_loss: 0.2930 - val_acc: 0.8892\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.29012\n",
      "Epoch 32/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.2892 - acc: 0.8917 - val_loss: 0.2919 - val_acc: 0.8891\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.29012\n",
      "Epoch 33/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.2870 - acc: 0.8924 - val_loss: 0.2945 - val_acc: 0.8879\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.29012\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00010890000325161964.\n",
      "Epoch 34/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.2824 - acc: 0.8943 - val_loss: 0.2886 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.29012 to 0.28864, saving model to model-emnist-nn0.h5\n",
      "Epoch 35/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.2805 - acc: 0.8948 - val_loss: 0.2904 - val_acc: 0.8901\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.28864\n",
      "Epoch 36/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.2800 - acc: 0.8943 - val_loss: 0.2881 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.28864 to 0.28808, saving model to model-emnist-nn0.h5\n",
      "Epoch 37/50\n",
      "101520/101520 [==============================] - 5s 52us/step - loss: 0.2798 - acc: 0.8935 - val_loss: 0.2867 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.28808 to 0.28674, saving model to model-emnist-nn0.h5\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101520/101520 [==============================] - 5s 51us/step - loss: 0.2773 - acc: 0.8955 - val_loss: 0.2876 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.28674\n",
      "Epoch 39/50\n",
      "101520/101520 [==============================] - 5s 50us/step - loss: 0.2784 - acc: 0.8944 - val_loss: 0.2878 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.28674\n",
      "Epoch 40/50\n",
      "101520/101520 [==============================] - 5s 50us/step - loss: 0.2778 - acc: 0.8953 - val_loss: 0.2896 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.28674\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 3.5936999920522795e-05.\n",
      "Epoch 41/50\n",
      "101520/101520 [==============================] - 5s 51us/step - loss: 0.2752 - acc: 0.8965 - val_loss: 0.2878 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.28674\n",
      "Epoch 42/50\n",
      "101520/101520 [==============================] - 5s 50us/step - loss: 0.2746 - acc: 0.8966 - val_loss: 0.2876 - val_acc: 0.8912\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.28674\n",
      "Epoch 43/50\n",
      "101520/101520 [==============================] - 5s 50us/step - loss: 0.2762 - acc: 0.8953 - val_loss: 0.2866 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.28674 to 0.28659, saving model to model-emnist-nn0.h5\n",
      "Epoch 44/50\n",
      "101520/101520 [==============================] - 5s 51us/step - loss: 0.2772 - acc: 0.8956 - val_loss: 0.2873 - val_acc: 0.8911\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.28659\n",
      "Epoch 45/50\n",
      "101520/101520 [==============================] - 5s 50us/step - loss: 0.2727 - acc: 0.8957 - val_loss: 0.2866 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.28659 to 0.28655, saving model to model-emnist-nn0.h5\n",
      "Epoch 46/50\n",
      "101520/101520 [==============================] - 5s 50us/step - loss: 0.2741 - acc: 0.8961 - val_loss: 0.2875 - val_acc: 0.8904\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.28655\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.185920958960196e-05.\n",
      "Epoch 47/50\n",
      "101520/101520 [==============================] - 5s 51us/step - loss: 0.2748 - acc: 0.8956 - val_loss: 0.2864 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.28655 to 0.28640, saving model to model-emnist-nn0.h5\n",
      "Epoch 48/50\n",
      "101520/101520 [==============================] - 5s 50us/step - loss: 0.2735 - acc: 0.8969 - val_loss: 0.2865 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.28640\n",
      "Epoch 49/50\n",
      "101520/101520 [==============================] - 5s 50us/step - loss: 0.2718 - acc: 0.8970 - val_loss: 0.2870 - val_acc: 0.8905\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.28640\n",
      "Epoch 50/50\n",
      "101520/101520 [==============================] - 5s 51us/step - loss: 0.2710 - acc: 0.8971 - val_loss: 0.2870 - val_acc: 0.8910\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.28640\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1e-05.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=4)\n",
    "\n",
    "parallel_model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.33, patience=3, min_lr=0.00001, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-emnist-nn0.h5', verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(patience=8, verbose=1)\n",
    "\n",
    "history=parallel_model.fit(train_data, train_labels, # Train the model using the training set...\n",
    "          batch_size=128, nb_epoch=50,\n",
    "          verbose=1, validation_split=0.1,callbacks=[earlystopper,checkpointer,reduce_lr]) # ...holding out 10% of the data for validation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "882/881 [==============================] - 19s 21ms/step - loss: 1.4976 - acc: 0.5582 - val_loss: 0.5047 - val_acc: 0.8296\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50467, saving model to model-emnist-nn.h5\n",
      "Epoch 2/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.6800 - acc: 0.7705 - val_loss: 0.4256 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50467 to 0.42561, saving model to model-emnist-nn.h5\n",
      "Epoch 3/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.5493 - acc: 0.8091 - val_loss: 0.4009 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.42561 to 0.40095, saving model to model-emnist-nn.h5\n",
      "Epoch 4/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.4882 - acc: 0.8272 - val_loss: 0.3922 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.40095 to 0.39222, saving model to model-emnist-nn.h5\n",
      "Epoch 5/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.4512 - acc: 0.8376 - val_loss: 0.3795 - val_acc: 0.8659\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.39222 to 0.37948, saving model to model-emnist-nn.h5\n",
      "Epoch 6/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.4229 - acc: 0.8457 - val_loss: 0.3778 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.37948 to 0.37784, saving model to model-emnist-nn.h5\n",
      "Epoch 7/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.4015 - acc: 0.8513 - val_loss: 0.3845 - val_acc: 0.8631\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.37784\n",
      "Epoch 8/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.3817 - acc: 0.8569 - val_loss: 0.3669 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.37784 to 0.36691, saving model to model-emnist-nn.h5\n",
      "Epoch 9/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.3710 - acc: 0.8608 - val_loss: 0.3735 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.36691\n",
      "Epoch 10/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.3610 - acc: 0.8629 - val_loss: 0.3646 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.36691 to 0.36459, saving model to model-emnist-nn.h5\n",
      "Epoch 11/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.3501 - acc: 0.8671 - val_loss: 0.3639 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.36459 to 0.36390, saving model to model-emnist-nn.h5\n",
      "Epoch 12/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.3368 - acc: 0.8717 - val_loss: 0.3631 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36390 to 0.36307, saving model to model-emnist-nn.h5\n",
      "Epoch 13/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.3297 - acc: 0.8734 - val_loss: 0.3635 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.36307\n",
      "Epoch 14/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.3233 - acc: 0.8734 - val_loss: 0.3681 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.36307\n",
      "Epoch 15/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.3188 - acc: 0.8763 - val_loss: 0.3663 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.36307\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00033000001567415896.\n",
      "Epoch 16/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.2916 - acc: 0.8868 - val_loss: 0.3535 - val_acc: 0.8779\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.36307 to 0.35350, saving model to model-emnist-nn.h5\n",
      "Epoch 17/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.2757 - acc: 0.8914 - val_loss: 0.3600 - val_acc: 0.8775\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.35350\n",
      "Epoch 18/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.2721 - acc: 0.8933 - val_loss: 0.3618 - val_acc: 0.8779\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.35350\n",
      "Epoch 19/50\n",
      "882/881 [==============================] - 18s 21ms/step - loss: 0.2704 - acc: 0.8936 - val_loss: 0.3668 - val_acc: 0.8779\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.35350\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00010890000325161964.\n",
      "Epoch 20/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.2583 - acc: 0.8974 - val_loss: 0.3624 - val_acc: 0.8791\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.35350\n",
      "Epoch 21/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.2572 - acc: 0.8990 - val_loss: 0.3620 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.35350\n",
      "Epoch 22/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.2555 - acc: 0.8987 - val_loss: 0.3634 - val_acc: 0.8785\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.35350\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.5936999920522795e-05.\n",
      "Epoch 23/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.2528 - acc: 0.9004 - val_loss: 0.3635 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.35350\n",
      "Epoch 24/50\n",
      "882/881 [==============================] - 18s 20ms/step - loss: 0.2509 - acc: 0.9002 - val_loss: 0.3631 - val_acc: 0.8793\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.35350\n",
      "Epoch 00024: early stopping\n",
      "18800/18800 [==============================] - 4s 191us/step\n",
      "[0.38007631676628234, 0.87755319148936173]\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    #shear_range = 0.05,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "datagen.fit(train_data)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "parallel_model.fit_generator(datagen.flow(train_data[:10000], train_labels[:10000],batch_size=128), \n",
    "                             steps_per_epoch=len(train_data) / 128, epochs = 50,\n",
    "          verbose=1, validation_data=(train_data[10000:], train_labels[10000:]),callbacks=[earlystopper,checkpointer,reduce_lr])\n",
    "\n",
    "\n",
    "print(parallel_model.evaluate(test_data, test_labels, verbose=1)) # Evaluate the trained model on the test set!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('model-emnist-nn0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11280/11280 [==============================] - 4s 353us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28639825538117836, 0.8908687943262411]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_data[-11280:],train_labels[-11280:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# error analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_name = {0:'0',1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',\n",
    "        8:'8',9:'9',10 :\"A\",11 :\"B\",12 :\"C\",13 :\"D\",14 :\"E\",15 :\"F\",\n",
    "        16 :\"G\",17 :\"H\",18 :\"I\",19 :\"J\",20 :\"K\",21 :\"L\",22 :\"M\",\n",
    "        23 :\"N\",24 :\"O\",25 :\"P\",26 :\"Q\",27 :\"R\",28 :\"S\",29 :\"T\",\n",
    "        30 :\"U\",31 :\"V\",32 :\"W\",33 :\"X\",34 :\"Y\",35 :\"Z\",36 :\"a\",\n",
    "        37:\"b\",38:\"d\",39:\"e\",40:\"f\",41:\"g\",42:\"h\",43:\"n\",44:\"q\",\n",
    "        45:\"r\",46:\"t\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101520.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(train_data[101520:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101534\n",
      "101544\n",
      "101545\n",
      "101549\n",
      "101556\n",
      "101568\n",
      "101572\n",
      "101597\n",
      "101599\n",
      "101602\n",
      "101605\n",
      "101608\n",
      "101609\n",
      "101634\n",
      "101637\n",
      "101640\n",
      "101649\n",
      "101653\n",
      "101654\n",
      "101656\n",
      "101666\n",
      "101672\n",
      "101701\n",
      "101702\n",
      "101704\n",
      "101712\n",
      "101724\n",
      "101735\n",
      "101742\n",
      "101743\n",
      "101745\n",
      "101760\n",
      "101765\n",
      "101784\n",
      "101788\n",
      "101805\n",
      "101817\n",
      "101842\n",
      "101851\n",
      "101853\n",
      "101857\n",
      "101871\n",
      "101879\n",
      "101887\n",
      "101891\n",
      "101898\n",
      "101907\n",
      "101916\n",
      "101928\n",
      "101931\n",
      "101932\n",
      "101936\n",
      "101941\n",
      "101944\n",
      "101952\n",
      "101983\n",
      "101996\n",
      "101997\n",
      "102008\n",
      "102009\n",
      "102010\n",
      "102022\n",
      "102023\n",
      "102025\n",
      "102031\n",
      "102039\n",
      "102046\n",
      "102050\n",
      "102051\n",
      "102056\n",
      "102064\n",
      "102065\n",
      "102068\n",
      "102073\n",
      "102074\n",
      "102095\n",
      "102102\n",
      "102103\n",
      "102106\n",
      "102108\n",
      "102111\n",
      "102113\n",
      "102121\n",
      "102129\n",
      "102141\n",
      "102153\n",
      "102159\n",
      "102164\n",
      "102176\n",
      "102183\n",
      "102209\n",
      "102217\n",
      "102235\n",
      "102238\n",
      "102254\n",
      "102259\n",
      "102262\n",
      "102268\n",
      "102283\n",
      "102287\n",
      "102309\n",
      "102310\n",
      "102319\n",
      "102328\n",
      "102337\n",
      "102345\n",
      "102350\n",
      "102357\n",
      "102372\n",
      "102373\n",
      "102377\n",
      "102387\n",
      "102400\n",
      "102402\n",
      "102408\n",
      "102415\n",
      "102438\n",
      "102442\n",
      "102447\n",
      "102448\n",
      "102468\n",
      "102476\n",
      "102479\n",
      "102497\n",
      "102501\n",
      "102509\n",
      "102515\n",
      "102517\n"
     ]
    }
   ],
   "source": [
    "for i in range(101520,101520+1000):\n",
    "    if np.argmax(prediction[i-101520])!=np.argmax(train_labels[i]):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: F\n",
      "preï¼š F\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADcFJREFUeJzt3W+oVPedx/HPx6sG8WpQRHNJ3cSUULIE1i43ssGNuJSUbCiYBNrUB4sLpfZBAy30wYYkUJ8shGXb7j4qWCK10KZbsK5CZFNJCsnCJsQEUVPXKuKq8UYbDLkxRK/X+90H97h7a+78znX+nbHf9wvCzJzvnJmvk/uZMzO/c87PESEA+cxrugEAzSD8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSmt/PJ7PN7oRAj0WE53K/jrb8th+xfcz2CdtPd/JYAPrL7e7bb3tI0u8lPSzprKS3JG2OiN8V1mHLD/RYP7b86ySdiIiTETEh6ZeSNnXweAD6qJPw3ynpzIzbZ6tlf8T2VtsHbB/o4LkAdFknP/jN9tHiMx/rI2K7pO0SH/uBQdLJlv+spNUzbn9O0rnO2gHQL52E/y1J99peY3uhpK9L2tudtgD0Wtsf+yNi0vZTkl6WNCRpR0S827XOAPRU20N9bT0Z3/mBnuvLTj4Abl2EH0iK8ANJEX4gKcIPJEX4gaT6ejw/2nPbbbcV6yMjIy1r8+cP7v/iycnJYn1sbKxYn5iYKNaZjaqMLT+QFOEHkiL8QFKEH0iK8ANJEX4gqcEdB0rELh+EVRrKk6THH3+8ZW14eLi47rx5zb3/j4+PF+u7d+8u1uuGAq9cuXLTPWXClh9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmKcvw/qxtKXLVtWrD/33HPF+pNPPtmytnDhwuK6dfsY9NKnn35arNe9bnX7AZw8efKme8qELT+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJNXROL/tU5I+lnRN0mREjHajqT81dWPpixYtKtbvueeettdv8nj9OnX/7pUrVxbrS5cu7WY76XRjJ5+/iYgPuvA4APpocDcLAHqq0/CHpN/Yftv21m40BKA/Ov3Yvz4iztleKWm/7f+OiNdm3qF6U+CNARgwHW35I+JcdXlB0m5J62a5z/aIGOXHQGCwtB1+24ttL7l+XdKXJR3pVmMAequTj/2rJO2uhrHmS/pFRPxHV7oC0HNthz8iTkr6iy72ktbU1FSxfvXq1WK9tB9B3T4Gly9fLtYvXbpUrNdZsmRJy9rQ0FBx3RUrVnRUL/3bmb6boT4gLcIPJEX4gaQIP5AU4QeSIvxAUpy6uw/qDqutm0b7rrvuavu5606PvWvXrmL91VdfLdYXLFhQrD/66KMtaw888EBx3X379hXrhw4dKtYZzitjyw8kRfiBpAg/kBThB5Ii/EBShB9IivADSTHO3wfz55df5tJhr1L9NNsTExMta2NjY8V1X3755WL9jTfeKNbr9lG44447WtbqTs19/PjxYn18fLxYRxlbfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IinH+Pli1alWxvmHDho7W/+CD1pMkv/7668V1jxwpz7NSd3rtulN/v/TSSy1rdb0dO3asWL9y5UqxjjK2/EBShB9IivADSRF+ICnCDyRF+IGkCD+QVO04v+0dkr4i6UJE3F8tWy7p3yTdLemUpK9FxIe9a/PW1unx/HXrL1q0qGVtzZo1xXWfeOKJYv3atWvFet0U3u+9917L2oEDB4rr1k1Njs7MZcv/U0mP3LDsaUmvRMS9kl6pbgO4hdSGPyJek3TxhsWbJO2sru+U9FiX+wLQY+1+518VEWOSVF2Wz8cEYOD0fN9+21slbe318wC4Oe1u+c/bHpGk6vJCqztGxPaIGI2I0TafC0APtBv+vZK2VNe3SNrTnXYA9Ett+G2/KOm/JH3B9lnb35D0vKSHbR+X9HB1G8AtpPY7f0RsblH6Upd7+ZN1++23F+tLly4t1ufNK79HL1++vGVt/fr1xXUffPDBYr1O3Vh86dz6e/aUPzA+++yzxfqHH5Z3LZmamirWs2MPPyApwg8kRfiBpAg/kBThB5Ii/EBSnLq7C+oOua07NffGjRuL9brTZ0dEy1rdUFzdFN6Tk5NtP7dUHm6rWxe9xZYfSIrwA0kRfiApwg8kRfiBpAg/kBThB5JinL8PhoeHi/XFixd39PgTExMta++//35x3d27dxfrdafmrjtstlQ/ePBgT58bZWz5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApxvn7oG68+pNPPuno8UvH5NeN42/btq1Yv3z5crHeyTH5newjgM6x5QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpGrH+W3vkPQVSRci4v5q2TZJ35T0h+puz0TEvl41OejqxqNPnTrVUX3t2rXFeunc+nX7GNSN49ed9x+3rrls+X8q6ZFZlv8oItZW/6UNPnCrqg1/RLwm6WIfegHQR51853/K9iHbO2wv61pHAPqi3fD/WNLnJa2VNCbpB63uaHur7QO2D7T5XAB6oK3wR8T5iLgWEVOSfiJpXeG+2yNiNCJG220SQPe1FX7bIzNuPi7pSHfaAdAvcxnqe1HSRkkrbJ+V9H1JG22vlRSSTkn6Vg97BNADteGPiM2zLH6hB73csurG+c+cOVOsnz59ulivO2a+VK/rrZPj8XFrYw8/ICnCDyRF+IGkCD+QFOEHkiL8QFKcursL5s8vv4wPPfRQsb5hw4ZifWho6KZ7Auqw5QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpBjn74Ph4eFiffHixX3qBPh/bPmBpAg/kBThB5Ii/EBShB9IivADSRF+ICnG+ftg3rzye2xdHegF/uqApAg/kBThB5Ii/EBShB9IivADSRF+IKna8Ntebfu3to/aftf2d6rly23vt328ulzW+3YBdMtctvyTkr4XEfdJ+itJ37b955KelvRKRNwr6ZXqNoBbRG34I2IsIt6prn8s6aikOyVtkrSzuttOSY/1qkkA3XdT3/lt3y3pi5LelLQqIsak6TcISSu73RyA3pnzvv22hyXtkvTdiBi3Pdf1tkra2l57AHplTlt+2ws0HfyfR8Svq8XnbY9U9RFJF2ZbNyK2R8RoRIx2o2EA3TGXX/st6QVJRyPihzNKeyVtqa5vkbSn++0B6JW5fOxfL+nvJB22fbBa9oyk5yX9yvY3JJ2W9NXetAigF2rDHxH/KanVF/wvdbcdAP3CHn5AUoQfSIrwA0kRfiApwg8kRfiBpDh1dx+Mj48X6x999FGxHhHdbAeQxJYfSIvwA0kRfiApwg8kRfiBpAg/kBThB5JinL8LpqamivUTJ04U60eOHCnW77vvvmJ9cnKyZa2uN+TFlh9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmKcvwvqxtL3799frB8+fLij+tWrV9tel/0A8mLLDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJue6c8LZXS/qZpDskTUnaHhH/anubpG9K+kN112ciYl/NY6U8Ab3daobzaQsXLizWR0ZG2n7uujkDLl682PZjYzBFRPkPrjKXnXwmJX0vIt6xvUTS27av77Xyo4j453abBNCc2vBHxJikser6x7aPSrqz140B6K2b+s5v+25JX5T0ZrXoKduHbO+wvazFOlttH7B9oKNOAXTVnMNve1jSLknfjYhxST+W9HlJazX9yeAHs60XEdsjYjQiRrvQL4AumVP4bS/QdPB/HhG/lqSIOB8R1yJiStJPJK3rXZsAuq02/J7+qfoFSUcj4oczls/8CfpxSeVT0AIYKHMZ6vtrSa9LOqzpoT5JekbSZk1/5A9JpyR9q/pxsPRYKYf6gH6a61Bfbfi7ifADvTfX8LOHH5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+IKl+T9H9gaT/mXF7RbVsEA1qb4Pal0Rv7epmb3fN9Y59PZ7/M09uHxjUc/sNam+D2pdEb+1qqjc+9gNJEX4gqabDv73h5y8Z1N4GtS+J3trVSG+NfucH0Jymt/wAGtJI+G0/YvuY7RO2n26ih1Zsn7J92PbBpqcYq6ZBu2D7yIxly23vt328upx1mrSGettm+73qtTto+9GGeltt+7e2j9p+1/Z3quWNvnaFvhp53fr+sd/2kKTfS3pY0llJb0naHBG/62sjLdg+JWk0IhofE7a9QdIlST+LiPurZf8k6WJEPF+9cS6LiH8YkN62SbrU9MzN1YQyIzNnlpb0mKS/V4OvXaGvr6mB162JLf86SSci4mRETEj6paRNDfQx8CLiNUkXb1i8SdLO6vpOTf/x9F2L3gZCRIxFxDvV9Y8lXZ9ZutHXrtBXI5oI/52Szsy4fVaDNeV3SPqN7bdtb226mVmsuj4zUnW5suF+blQ7c3M/3TCz9MC8du3MeN1tTYR/ttlEBmnIYX1E/KWkv5X07erjLeZmTjM398ssM0sPhHZnvO62JsJ/VtLqGbc/J+lcA33MKiLOVZcXJO3W4M0+fP76JKnV5YWG+/k/gzRz82wzS2sAXrtBmvG6ifC/Jele22tsL5T0dUl7G+jjM2wvrn6Ike3Fkr6swZt9eK+kLdX1LZL2NNjLHxmUmZtbzSythl+7QZvxupGdfKqhjH+RNCRpR0T8Y9+bmIXtezS9tZemj3j8RZO92X5R0kZNH/V1XtL3Jf27pF9J+jNJpyV9NSL6/sNbi9426iZnbu5Rb61mln5TDb523Zzxuiv9sIcfkBN7+AFJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSOp/Acw0PIPfZn2jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 101830\n",
    "plt.imshow(train_data[idx][:,:,0],cmap='gray')\n",
    "print(\"Label:\",id_name[np.argmax(train_labels[idx])])\n",
    "print(\"preï¼š\",id_name[np.argmax(prediction[idx-101520])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 9\n",
    "plt.imshow(train_data[idx][:,:,0],cmap='gray')\n",
    "print(id_name[np.argmax(train_labels[idx])])\n",
    "#print(np.argmax(train_labels[idx])-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e960b9bdbc3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./real/j.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "tmp = plt.imread(\"./real/j.png\")[:,:,0]\n",
    "plt.imshow(1.0*(tmp<0.5), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x127bfe240>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txtt = 1.0*(tmp<0.5)\n",
    "txtt = cv2.resize(txtt, (28, 28))\n",
    "plt.imshow(txtt,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./real/3.png', './real/6.png', './real/7.png', './real/A.png', './real/B.png', './real/e.png', './real/h.png', './real/j.png', './real/k.png', './real/m.png', './real/p.png', './real/Q.png', './real/R.png', './real/w.png', './real/x.png', './real/z.png']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "real_test= glob.glob(\"./real/*\")\n",
    "print(real_test)\n",
    "\n",
    "\n",
    "test_R_1 = []    \n",
    "for e in real_test:\n",
    "    tmp = plt.imread(e)[:,:,0]\n",
    "    tmp = 1.0*(tmp<0.67)\n",
    "    sss =  cv2.resize(tmp, (28, 28))\n",
    "    sss = 1.0*(sss>0.01)\n",
    "    sss = sss.reshape(28,28,1)\n",
    "    test_R_1.append(sss)\n",
    "    \n",
    "test_R_2 = []    \n",
    "for e in real_test:\n",
    "    tmp = plt.imread(e)[:,:,0]\n",
    "    tmp = 1.0*(tmp<0.37)\n",
    "    sss =  cv2.resize(tmp, (28, 28))\n",
    "    sss = 1.0*(sss>0.01)\n",
    "    sss = sss.reshape(28,28,1)\n",
    "    test_R_2.append(sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preR_1 = model.predict(np.array(test_R_1))\n",
    "preR_2 = model.predict(np.array(test_R_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre 0.67ï¼š 3 pre 0.37ï¼š 3\n",
      "pre 0.67ï¼š 6 pre 0.37ï¼š 6\n",
      "pre 0.67ï¼š 7 pre 0.37ï¼š 7\n",
      "pre 0.67ï¼š A pre 0.37ï¼š A\n",
      "pre 0.67ï¼š B pre 0.37ï¼š B\n",
      "pre 0.67ï¼š e pre 0.37ï¼š e\n",
      "pre 0.67ï¼š h pre 0.37ï¼š h\n",
      "pre 0.67ï¼š G pre 0.37ï¼š G\n",
      "pre 0.67ï¼š B pre 0.37ï¼š K\n",
      "pre 0.67ï¼š M pre 0.37ï¼š M\n",
      "pre 0.67ï¼š P pre 0.37ï¼š P\n",
      "pre 0.67ï¼š Q pre 0.37ï¼š Q\n",
      "pre 0.67ï¼š A pre 0.37ï¼š R\n",
      "pre 0.67ï¼š 1 pre 0.37ï¼š W\n",
      "pre 0.67ï¼š X pre 0.37ï¼š X\n",
      "pre 0.67ï¼š Z pre 0.37ï¼š Z\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(preR_1)):\n",
    "    print(\"pre 0.67ï¼š\",id_name[np.argmax(preR_1[i])], \"pre 0.37ï¼š\",id_name[np.argmax(preR_2[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preï¼š A\n"
     ]
    }
   ],
   "source": [
    "print(\"preï¼š\",id_name[np.argmax(preR[8])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7638c3844a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_R_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(test_R_1[11][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1204f1240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_R_2[7][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
